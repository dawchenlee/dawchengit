### 信息论
交叉熵是信息论中的一个概念，要想了解交叉熵的本质，需要先从最基本的概念讲起。
### 一、信息量
首先是信息量。假设我们听到了两件事，分别如下：  
事件A：巴西队进入了2018世界杯决赛圈。  
事件B：中国队进入了2018世界杯决赛圈。  
仅凭直觉来说，显而易见事件B的信息量比事件A的信息量要大。究其原因，是因为事件A发生的概率很大，事件B发生的概率很小。  
所以当越不可能的事件发生了，我们获取到的信息量就越大。越可能发生的事件发生了，我们获取到的信息量就越小。那么信息量应该和事件发生的概率有关。  
![image](https://github.com/dawchenlee/dawchengit/blob/master/machine%20learning/photo/%E4%BF%A1%E6%81%AF%E9%87%8F%E5%9B%BE.png?raw=true)
